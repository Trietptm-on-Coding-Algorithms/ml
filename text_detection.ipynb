{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_detection.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mandliya/ml/blob/master/text_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeqGLh767q57",
        "colab_type": "text"
      },
      "source": [
        "### Get the repository (TextSnake)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHkrCxMU7Q-o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "56f03725-d87f-4e68-9c7f-3caf83deb5c3"
      },
      "source": [
        "!git clone https://github.com/princewang1994/TextSnake.pytorch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'TextSnake.pytorch'...\n",
            "remote: Enumerating objects: 396, done.\u001b[K\n",
            "remote: Total 396 (delta 0), reused 0 (delta 0), pack-reused 396\u001b[K\n",
            "Receiving objects: 100% (396/396), 1.64 MiB | 9.75 MiB/s, done.\n",
            "Resolving deltas: 100% (244/244), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_jSjPoO8N4u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c05359a4-6860-46a6-a87d-02d726777e4f"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data  sample_data  TextSnake.pytorch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTS6bd788EIl",
        "colab_type": "text"
      },
      "source": [
        "### Add it to system path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0S-Ut9oT7m5q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/TextSnake.pytorch')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_okZ3eLsEnt7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4MuetCI9CTd",
        "colab_type": "text"
      },
      "source": [
        "### Download the pretrained model from google link.\n",
        "\n",
        "Model is [here](https://drive.google.com/open?id=1YvsuxKH9M-Gseur9gc-SZJb3pCpTUddi) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLLm1LxG9aIZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "61915aeb-45d6-42c6-a604-8ae02a8cfebd"
      },
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Download a file based on its file ID.\n",
        "#\n",
        "file_id = '1YvsuxKH9M-Gseur9gc-SZJb3pCpTUddi'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('data/textsnake_vgg_180.pth')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10kB 25.9MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 2.1MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 3.0MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 2.0MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 2.5MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 3.0MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 3.4MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 3.8MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 4.3MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 3.4MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112kB 3.4MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 3.4MB/s eta 0:00:01\r\u001b[K     |████▎                           | 133kB 3.4MB/s eta 0:00:01\r\u001b[K     |████▋                           | 143kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 163kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 174kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 194kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 204kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 225kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 235kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 256kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 266kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 286kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 296kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 317kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 327kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 348kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 358kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 378kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 389kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 409kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 419kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 440kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 450kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 471kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 481kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 501kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 512kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 532kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 542kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 563kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 573kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 593kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 604kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 624kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 634kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 645kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 655kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 665kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 675kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 686kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 696kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 706kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 716kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 727kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 737kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 747kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 757kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 768kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 778kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 788kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 798kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 808kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 819kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 829kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 839kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 849kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 860kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 870kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 880kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 890kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 901kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 911kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 921kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 931kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 942kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 952kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 962kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 972kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 983kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 993kB 3.4MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afVOMhmHOSZF",
        "colab_type": "text"
      },
      "source": [
        "imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2gL7er3OVNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "from IPython.display import display, HTML, clear_output\n",
        "from ipywidgets import widgets, Layout\n",
        "from io import BytesIO\n",
        "\n",
        "import os\n",
        "import time\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.utils.data as data\n",
        "\n",
        "#from dataset.deploy import DeployDataset\n",
        "from network.textnet import TextNet\n",
        "from util.detection import TextDetector\n",
        "from util.augmentation import BaseTransform\n",
        "from util.config import config as cfg, update_config, print_config\n",
        "from util.option import BaseOptions\n",
        "from util.visualize import visualize_detection\n",
        "from util.misc import mkdirs, rescale_result\n",
        "from util.config import config as cfg, update_config, print_config\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# pytorch provides a function to convert PIL images to tensors.\n",
        "pil2tensor = transforms.ToTensor()\n",
        "tensor2pil = transforms.ToPILImage()\n",
        "\n",
        "import requests\n",
        "\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1l1XOCAKuXc",
        "colab_type": "text"
      },
      "source": [
        "### Some utilities to get user input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQbSxtLmKhmV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def init_widgets_TD(url):\n",
        "  image_text = widgets.Text(\n",
        "    description=\"Image URL\", layout=Layout(minwidth=\"70%\")\n",
        "  )\n",
        "  image_text.value = url\n",
        "  submit_button = widgets.Button(description=\"Ask Text Detection!\")\n",
        "\n",
        "  display(image_text)\n",
        "  display(submit_button)\n",
        "\n",
        "  submit_button.on_click(lambda b: on_button_click_td(\n",
        "      b, image_text\n",
        "  ))\n",
        "  \n",
        "  return image_text\n",
        "  \n",
        "  \n",
        "def get_actual_image(image_path):\n",
        "      if image_path.startswith('http'):\n",
        "          path = requests.get(image_path, stream=True).raw\n",
        "      else:\n",
        "          path = image_path\n",
        "      \n",
        "      return path\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2IAxUodMQx9",
        "colab_type": "text"
      },
      "source": [
        "### Set up configuration for text detection\n",
        "\n",
        "change here if you need to adjust text detection parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjjIbqX6MOsF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from easydict import EasyDict\n",
        "import torch\n",
        "\n",
        "def create_text_detection_config():\n",
        "  config = EasyDict()\n",
        "  config.num_workers = 1\n",
        "  config.batch_size = 1\n",
        "  config.max_epoch = 100\n",
        "  config.start_epoch = 0\n",
        "  config.lr = 1e-4\n",
        "  config.cuda = True\n",
        "  config.n_disk = 15\n",
        "  config.output_dir = 'output'\n",
        "  config.input_size = 512\n",
        "  # max polygon per image\n",
        "  config.max_annotation = 200\n",
        "\n",
        "  # max point per polygon\n",
        "  config.max_points = 20\n",
        "\n",
        "  # use hard examples (annotated as '#')\n",
        "  config.use_hard = True\n",
        "\n",
        "  # demo tr threshold\n",
        "  config.tr_thresh = 0.6\n",
        "\n",
        "  # demo tcl threshold\n",
        "  config.tcl_thresh = 0.4\n",
        "\n",
        "  # expand ratio in post processing\n",
        "  config.post_process_expand = 0.3\n",
        "\n",
        "  # merge joined text instance when predicting\n",
        "  config.post_process_merge = False\n",
        "  config.device = torch.device('cuda') if config.cuda else torch.device('cpu')\n",
        "  config.detection_model_path = 'data/textsnake_vgg_180.pth'\n",
        "  return config\n",
        "\n",
        "\n",
        "def to_device(cfg, *tensors):\n",
        "    if len(tensors) < 2:\n",
        "        return tensors[0].to(cfg.device)\n",
        "    return (t.to(cfg.device) for t in tensors)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKa_Hi6bFxDw",
        "colab_type": "text"
      },
      "source": [
        "### Create the text detection model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQ2Gq0ZkBbAK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextDetectorModel:\n",
        "  def __init__(self, cfg):\n",
        "    \"\"\"Creates a text detection model\"\"\"\n",
        "    self.config = cfg\n",
        "    self.model = TextNet(is_training=False, backbone='vgg')\n",
        "    self.model.load_model(cfg.detection_model_path)\n",
        "    \n",
        "    self.model = self.model.to(cfg.device)\n",
        "    if cfg.cuda:\n",
        "        cudnn.benchmark = True\n",
        "    self.detector = TextDetector(self.model, tr_thresh=cfg.tr_thresh,\n",
        "                                 tcl_thresh=cfg.tcl_thresh)\n",
        "\n",
        "  \n",
        "  def rescale_result(self, image, contours, H, W):\n",
        "    ori_H, ori_W = image.shape[:2]\n",
        "    image = cv2.resize(image, (W, H))\n",
        "    for cont in contours:\n",
        "        cont[:, 0] = (cont[:, 0] * W / ori_W).astype(int)\n",
        "        cont[:, 1] = (cont[:, 1] * H / ori_H).astype(int)\n",
        "    return image, contours\n",
        "\n",
        "  def predict(self, image, H, W):\n",
        "    image = to_device(self.config, image)\n",
        "    contours, output = self.detector.detect(image)\n",
        "    image, contours = self.rescale_result(image, contours, H, W)\n",
        "    return image, contours\n",
        "    \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOz0oaZLMGIu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def on_button_click_td(b, image_text):\n",
        "  clear_output()\n",
        "  image_path = get_actual_image(image_text.value)\n",
        "  image = Image.open(image_path)\n",
        "  config = create_text_detection_config()\n",
        "  text_detection_model = TextDetectorModel(config)\n",
        "  tensor = pil2tensor(image)\n",
        "  reshaped = torch.unsqueeze(tensor, 0)#tensor.permute(2, 0, 1).unsqueeze(0)\n",
        "  image, contours = text_detection_model.predict(reshaped, 240, 240)\n",
        "  display(image)\n",
        "  print(contours)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtP66QgWEkja",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 868
        },
        "outputId": "7b3cf411-e6a4-4e9b-f246-e704e9186c9e"
      },
      "source": [
        "\n",
        "image_text = init_widgets_TD(\n",
        "    \"http://images.cocodataset.org/train2017/000000505539.jpg\", \n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading from data/textsnake_vgg_180.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-a7e4cc23d395>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   submit_button.on_click(lambda b: on_button_click_td(\n\u001b[0;32m---> 13\u001b[0;31m       \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   ))\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-63-93f8d4f25326>\u001b[0m in \u001b[0;36mon_button_click_td\u001b[0;34m(b, image_text)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil2tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mreshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#tensor.permute(2, 0, 1).unsqueeze(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontours\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_detection_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m240\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m240\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontours\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-1ff3980b4c36>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, image, H, W)\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mcontours\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontours\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrescale_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontours\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontours\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/TextSnake.pytorch/util/detection.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;31m# find text contours\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0mcontours\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect_contours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtcl_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msin_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcos_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mradii_pred\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (n_tcl, 3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         output = {\n",
            "\u001b[0;32m/content/TextSnake.pytorch/util/detection.py\u001b[0m in \u001b[0;36mdetect_contours\u001b[0;34m(self, image, tr_pred, tcl_pred, sin_pred, cos_pred, radii_pred)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# find tcl in each predicted mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0mdetect_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_tcl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtcl_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msin_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcos_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mradii_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetect_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_pred_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/TextSnake.pytorch/util/detection.py\u001b[0m in \u001b[0;36mbuild_tcl\u001b[0;34m(self, tcl_pred, sin_pred, cos_pred, radii_pred)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;31m# find disjoint regions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mtcl_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_hole\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtcl_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0mtcl_contours\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindContours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtcl_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETR_TREE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHAIN_APPROX_SIMPLE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcont\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtcl_contours\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeKMBxd-Gltk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}